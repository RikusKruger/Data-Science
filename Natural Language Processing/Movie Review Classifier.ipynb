{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "# load the dataset using the load_data function (25 000 samples)\n",
    "\n",
    "vocabulary_size = 5000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Review---\n",
      "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
      "\n",
      "---Label---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('---Review---')\n",
    "print(f'{x_train[6]}\\n')\n",
    "print('---Label---')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2697\n",
      "Minimum review length: 14\n"
     ]
    }
   ],
   "source": [
    "# Getting maximum and minimum words per review\n",
    "\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((x_train + x_test), key=len))))\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((x_test + x_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data so that all reviews are the same length (500 words)\n",
    "max_words = 500\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 13:29:53.164427 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0807 13:29:53.175398 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 13:29:53.176396 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 580,501\n",
      "Trainable params: 580,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model with an embedded layer 100 LTSM layers, one dense layer and sigmoid output\n",
    "embedding_size=100 # Set embedding size to 100\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 13:29:53.338961 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with \"mean squared error\" loss, adam optimizer and monotoring accuracy metrics\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 13:29:53.481580 10772 deprecation.py:323] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0807 13:29:53.769837 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0807 13:29:53.826657 10772 deprecation_wrapper.py:119] From C:\\Users\\Clutch\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "14976/24936 [=================>............] - ETA: 1:44 - loss: 0.1883 - acc: 0.7197"
     ]
    }
   ],
   "source": [
    "# Train the model on training data over 3 epochs with a batch size of 64\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "x_valid, y_valid = x_train[:batch_size], y_train[:batch_size]\n",
    "x_train2, y_train2 = x_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(x_train2, y_train2, validation_data=(x_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of the model using evaluate function\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random movie review from a random website\n",
    "\n",
    "review = \"\"\"This renamed renamed film is going to be liked. Yes, it has all the elements of a good slasher, including the knives, the masks (think Friday the 13th), the creepy music, and a really hot couple of girls. But wait, there`s more. One of them gets even. She does this with some cool tactics, including two dips in the campus pool. She swings for the fences. She is a chemistry whiz. When she is randomly picked to be the victim of one cell of crooks among several, she ends up being the one smarter than all of them. Well, as smart as a college junior could be, I guess.\n",
    "\n",
    "There are problems, as in all lower budget horror flicks. Someone goes out for ice cream on a foggy cold night. Nobody seems to be able to communicate with their friends. Alone on a campus by yourself, you keep all the lights on. If you are going for a swim, you would strip down so that your clothes would not slop tell-tale water all over the place. And you would not send the audience on a chemistry wild-goose chase as they try to figure out how water makes fire. Nobody inhales loudly after surfacing in a pool when the bad guys might be right there. Trivial errors, but not enough to detract too much.\n",
    "\n",
    "If you like your heroes strong and wily, go see this one. If you like a little blood, not a lot, then this one is for you. Highly recommended\"\"\"\n",
    "\n",
    "\n",
    "# Import Tokenizer from keras to preprocess the string for the model to predict\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "\n",
    "# Use the tokenizer to convert the string into values the model can use\n",
    "review = tokenizer.texts_to_sequences(review)\n",
    "flat_list = []\n",
    "for sublist in review:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "\n",
    "flat_list = [flat_list]\n",
    "\n",
    "# add padding to review to make sure it has the right length\n",
    "review = sequence.pad_sequences(flat_list, maxlen=max_words)\n",
    "# print(f\"Converted string:\\n{review}\")\n",
    "\n",
    "# Predict whether the review is positive or negative.\n",
    "model.predict(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted a value of ~0.75. Because our results are 1-positive and 0-negative and this value is closer to one than 0 we can see that the model predicted a positive review and is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
